# LinkReview

- Here we collect all the works that may be useful for writing our paper
- We divide these works by topic in order to structure them

> [!NOTE]
> This review table will be updated, so it is not a final version.

| Topic | Title | Year | Authors | Paper | Code | Summary |
| :--- | :--- | :---: | :--- | :---: | :---: | :--- |
| Main Articles | Unraveling the Hessian: A Key to Smooth Convergence in Loss Function Landscapes | 2024 | Nikita Kiselev et al. | [arXiv/DOI](https://arxiv.org/abs/2409.11995) | [GitHub]() | Fully-Contedet NN Landscape study |
|  | ConvNets Landscape Convergence: Hessian-Based Analysis of Matricized Networks | 2024 | Vladislav Meshkov et al. | [arXiv/DOI](https://ieeexplore.ieee.org/document/10899113) | [GitHub]() | ConvNet Landscape study |
|  | Stagewise Development in Transformers and the Geometry of the Loss Landscape | 2024 | Currently anonymos | [OpenReview](https://openreview.net/forum?id=xEZiEhjTeq) | [GitHub]() | Work developing a geometric view of the loss function landscape without mention of the minimum required sample size |
|  | Kiselev BS Thesis Paper | 2024 | Nikita Kiselev et al. | [arXiv/DOI]() | [GitHub]() | A work that explores the desired area and reveals the basic definitions |
| Transformers | Attention Is All You Need | 2017 | Ashish Vaswani et al. | [arXiv/DOI](https://arxiv.org/abs/1706.03762) | [GitHub]() | Basic work on transformer architecture and attention mechanism |
|  | TODO | TODO | TODO | TODO | TODO | TODO |
|  | TODO | TODO | TODO | TODO | TODO | TODO |
