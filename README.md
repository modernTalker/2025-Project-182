# Convergence of the loss function surface in transformer neural network architectures

<!-- Change `modernTalker/2025-Project-182` to `intsystems/your-repository`-->
[![License](https://badgen.net/github/license/modernTalker/2025-Project-182?color=green)](https://github.com/modernTalker/2025-Project-182/blob/main/LICENSE)
[![GitHub Contributors](https://img.shields.io/github/contributors/modernTalker/2025-Project-182)](https://github.com/modernTalker/2025-Project-182/graphs/contributors)
[![GitHub Issues](https://img.shields.io/github/issues-closed/modernTalker/2025-Project-182.svg?color=0088ff)](https://github.com/modernTalker/2025-Project-182/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr-closed/modernTalker/2025-Project-182.svg?color=7f29d6)](https://github.com/modernTalker/2025-Project-182/pulls)

<table>
    <tr>
        <td align="left"> <b> Author </b> </td>
        <td> Egor Petrov </td>
    </tr>
    <tr>
        <td align="left"> <b> Consultant </b> </td>
        <td> Nikita Kiselev, PhD/DSc </td>
    </tr>
    <tr>
        <td align="left"> <b> Advisor </b> </td>
        <td> Andrey Grabovoy, PhD/DSc </td>
    </tr>
</table>

## Assets

- [LinkReview](LINKREVIEW.md)
- [Code](code)
- [Paper](paper)
- [Slides](slides)

## Abstract

TODO

## Citation

If you find our work helpful, please cite us.
```BibTeX
@article{citekey,
    title={Title},
    author={Egor Petrov, Nikita Kiselev (consultant), Andrey Grabovoy (advisor)},
    year={2025}
}
```

## Licence

Our project is MIT licensed. See [LICENSE](LICENSE) for details.
